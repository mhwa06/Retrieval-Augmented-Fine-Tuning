{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3cN_eqBwrMZ"
      },
      "source": [
        "# Preparing training data for RAFT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LqPRqZvwq21"
      },
      "source": [
        "We'll follow these steps to create the training dataset:\n",
        "\n",
        "- **Collect Domain-Specific Documents**: Gather documents relevant to the domain you want to specialize the LLM in (e.g., medical documents for PubMed, legal documents, API documentation for software).\n",
        "- **Chunk the file into Documents**\n",
        "- For each Document chunk, generate a set of Questions that can be answered from the Document\n",
        "- For each Document-Question pair, create a list of documents using:\n",
        "  - **Golden Document (D*)**: Document that contains the answer to the question.\n",
        "  - **Distractor Documents (Dk)**: Documents that do not contain relevant information.\n",
        "- **Question-Answer-Document Triplets**: From each Document-Question pair, generate a factual Answer based on the Golden Document.\n",
        "- **Add disctractor documents**\n",
        "- **Generate and save dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHElCpNpqvqC",
        "outputId": "7e48f4a2-f27f-4934-98e3-e5de7f14b5d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.10)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.10-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.7.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.10 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.13)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.46)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.4)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.13.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.7.3)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.21.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.1.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (26.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (0.14.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (0.3.6)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain) (1.12.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.1.10-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.7.1-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.0/331.0 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.1-py3-none-any.whl (35 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, pypdf, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-openai, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-openai-1.1.10 langchain-text-splitters-1.1.1 marshmallow-3.26.2 mypy-extensions-1.1.0 pypdf-6.7.1 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain langchain-community langchain-openai pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhOYTMFuxWBB"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4jL_f8sMqmcG"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypJjzxHV03ru"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kc9RcDnmkAUA",
        "outputId": "d801c199-0328-440d-a66c-d87c65b2e52c"
      },
      "outputs": [],
      "source": [
        "# access OPENAI api key from colab secrets\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itbFHquaYjgg"
      },
      "source": [
        "## Setting up the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZuC8Bvho3sAI"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(model_name=\"gpt-4o-mini\", api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snryQtBixYMq"
      },
      "source": [
        "## Loading and chunking documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yM-9onwtquOq"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_and_chunk_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Load a PDF file and chunk it semantically using LangChain.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the PDF file\n",
        "\n",
        "    Returns:\n",
        "        list: List of semantic chunks\n",
        "    \"\"\"\n",
        "    # Initialize the PDF loader\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "\n",
        "    # Load the document\n",
        "    pages = loader.load()\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=3000,\n",
        "        chunk_overlap=500,\n",
        "        length_function=len,\n",
        "        is_separator_regex=False,\n",
        "    )\n",
        "\n",
        "    chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yxZ3MkSey7Xw"
      },
      "outputs": [],
      "source": [
        "# calling the function to chunk the finance PDF\n",
        "chunks = load_and_chunk_pdf(\"/content/AgenticRAG.pdf\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKC8kBSbq-lg",
        "outputId": "0d92c646-ac4d-4686-bf1c-5803f7b72ae6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of chunks: 54\n",
            "\n",
            "Chunk 1:\n",
            "Content length: 2966\n",
            "Metadata: {'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20260221163449', 'source': '/content/AgenticRAG.pdf', 'total_pages': 39, 'page': 0, 'page_label': '1'}\n",
            "--------------------------------------------------\n",
            "\n",
            "Chunk 2:\n",
            "Content length: 528\n",
            "Metadata: {'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20260221163449', 'source': '/content/AgenticRAG.pdf', 'total_pages': 39, 'page': 0, 'page_label': '1'}\n",
            "--------------------------------------------------\n",
            "\n",
            "Chunk 3:\n",
            "Content length: 2908\n",
            "Metadata: {'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20260221163449', 'source': '/content/AgenticRAG.pdf', 'total_pages': 39, 'page': 1, 'page_label': '2'}\n",
            "--------------------------------------------------\n",
            "\n",
            "Chunk 4:\n",
            "Content length: 2601\n",
            "Metadata: {'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20260221163449', 'source': '/content/AgenticRAG.pdf', 'total_pages': 39, 'page': 1, 'page_label': '2'}\n",
            "--------------------------------------------------\n",
            "\n",
            "Chunk 5:\n",
            "Content length: 1441\n",
            "Metadata: {'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20260221163449', 'source': '/content/AgenticRAG.pdf', 'total_pages': 39, 'page': 2, 'page_label': '3'}\n",
            "--------------------------------------------------\n",
            "\n",
            "Chunk 6:\n",
            "Content length: 2047\n",
            "Metadata: {'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20260221163449', 'source': '/content/AgenticRAG.pdf', 'total_pages': 39, 'page': 3, 'page_label': '4'}\n",
            "--------------------------------------------------\n",
            "\n",
            "Chunk 7:\n",
            "Content length: 2250\n",
            "Metadata: {'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20260221163449', 'source': '/content/AgenticRAG.pdf', 'total_pages': 39, 'page': 4, 'page_label': '5'}\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"Total number of chunks: {len(chunks)}\")\n",
        "\n",
        "# Print information about each chunk\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"\\nChunk {i+1}:\")\n",
        "    print(f\"Content length: {len(chunk.page_content)}\")\n",
        "    print(f\"Metadata: {chunk.metadata}\")\n",
        "    print(\"-\" * 50)\n",
        "    if (i>5):\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1-h7zPSzF9D"
      },
      "source": [
        "Lets actually look into the contents of the chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEjw4fs640pU",
        "outputId": "d50c1429-5ce4-4c2d-9756-10df4ffdc54f",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20260221163449', 'source': '/content/AgenticRAG.pdf', 'total_pages': 39, 'page': 27, 'page_label': '28'}, page_content='Figure 23: An Overview of Agentic Document Workflows (ADW)\\n[36]\\nUse Case: Invoice Payments Workflow\\nPrompt: Generate a payment recommendation report based on the submitted invoice and associated vendor\\ncontract terms.\\nSystem Process (ADW Workflow):\\n1. Parse the invoice to extract key details such as invoice number, date, vendor information, line items,\\nand payment terms.\\n2. Retrieve the corresponding vendor contract to verify payment terms and identify any applicable\\ndiscounts or compliance requirements.\\n3. Generate a payment recommendation report that includes original amount due, potential early payment\\ndiscounts, budget impact analysis, and strategic payment actions.\\nResponse: Integrated Response: \"Invoice INV-2025-045 for $15,000.00 has been processed. An early payment\\ndiscount of 2% is available if paid by 2025-04-10, reducing the amount due to $14,700.00. A bulk order discount\\nof 5% was applied as the subtotal exceeded $10,000.00. It is recommended to approve early payment to save\\n2% and ensure timely fund allocation for upcoming project phases.\"\\nKey Features and Advantages\\n• State Maintenance: Tracks document context and workflow stage, ensuring consistency across processes.\\n• Multi-Step Orchestration: Handles complex workflows involving multiple components and external tools.\\n• Domain-Specific Intelligence: Applies tailored business rules and guidelines for precise recommendations.\\n• Scalability: Supports large-scale document processing with modular and dynamic agent integration.\\n• Enhanced Productivity: Automates repetitive tasks while augmenting human expertise in decision-making.\\n28')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_index = random.randint(0, len(chunks)-1)\n",
        "chunk = chunks[sample_index]\n",
        "chunk"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
